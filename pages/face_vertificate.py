from servicess.Face_Vertification.models.sface import SFace
from servicess.Face_Vertification.models.yunet import YuNet
import requests
import random
import time
import argparse
import os
import sys
import tempfile
import re
import unicodedata
import numpy as np
import pandas as pd
import cv2 as cv
from io import BytesIO
from google.cloud.firestore import FieldFilter as fil
from PIL import Image, ImageOps
from google.cloud import firestore, storage
from firebase_admin import credentials
import toml
import json
import firebase_admin
import streamlit as st

# from services.face_verification.yunet import YuNet
# from services.face_verification.sface import SFace

st.title("üéàFace Verification App")

# Kh·ªüi t·∫°o Firestore Client b·∫±ng credentials t·ª´ file JSON
db = firestore.Client.from_service_account_info(st.secrets)


bucket = storage.Client.from_service_account_info(
    st.secrets).get_bucket('face-vertificates.appspot.com')

lst_folder = ['HoangHao', 'NgoVanHai', 'TruongDoan', 'NguyenPhuocBinh',
              'NguyenVuHoangChuong', 'TranThiThanhHue', 'LeBaNhatMinh']


def get_url_Image(path):
    blob = bucket.blob(path)
    blob.make_public()
    image_path = blob.public_url
    url = f"<img src = '{image_path}' width='100'>"
    return url

# def List_folder():
#     for i in range(len(lst_folder)):
#         blobs = bucket.list_blobs(prefix = lst_folder[i])
#         file_list = [blob.name for blob in blobs]
#         public_url1 = read_Image(file_list[1])
#         lst_ChanDung.append(f"<img src='{public_url1}' width='100'>")
#         if len(file_list) <= 2:
#             lst_TheSV.append(f"<img src='{public_url1}' width='100'>")
#         else:
#             public_url2 = read_Image(file_list[2])
#             lst_TheSV.append(f"<img src='{public_url2}' width='100'>")
#         # print(list(blobs.prefixes))


@st.cache_data(ttl="2h")
def get_Info():
    lst_Ten = []
    lst_Masv = []
    lst_ChanDung = []
    lst_TheSV = []
    doc = db.collection('face-vertificate').get()
    lent = len(doc)
    doc = db.collection("face-vertificate").stream()
    for i in doc:
        doc_data = i.to_dict()
        Ten = doc_data.get('hoten')
        Masv = doc_data.get('masv')
        url_ChanDung = doc_data.get('ChanDung')
        url_TheSV = doc_data.get('TheSV')
        lst_Ten.append(Ten)
        lst_Masv.append(Masv)
        # lst_Nganh.append(Nganh)
        lst_ChanDung.append(url_ChanDung)
        lst_TheSV.append(url_TheSV)
    return lst_Ten, lst_Masv, lst_ChanDung, lst_TheSV


@st.cache_data(ttl="2h")
def Table_of_Data():
    doc = db.collection('face-vertificate').get()
    lent = len(doc)
   #  lst_STT = np.arange(1, lent + 1, 1)
    lst_Ten, lst_Masv, lst_ChanDung, lst_TheSV = get_Info()
    data = {
        #   "STT": lst_STT,
        "HoTen": lst_Ten,
        "MaSV": lst_Masv,
        # "Ng√†nh": lst_Nganh,
        "·∫¢nh ch√¢n dung": lst_ChanDung,
        "·∫¢nh th·∫ª sv": lst_TheSV
    }
    df = pd.DataFrame(data)
    # st.dataframe(df)
    # st.write(df.to_html(escape=False, index=False), unsafe_allow_html=True)
    html = df.to_html(escape=False, index=False)
    st.write(html, unsafe_allow_html=True)


def add_Image_url():
    doc = db.collection('face-vertificate').get()
    lent = len(doc)
    for i in range(lent):
        blobs = bucket.list_blobs(prefix=lst_folder[i])
        file_list = [blob.name for blob in blobs]
        public_url1 = get_url_Image(file_list[1])
        doc_ref = db.collection('face-vertificate').document(str(i + 1))
        public_url2 = ""
        if len(file_list) > 2:
            public_url2 = get_url_Image(file_list[2])
        # print(public_url1, public_url2)
        doc_ref.update({
            'ChanDung': public_url1,
            'TheSV': public_url2
        })


def remove_accents(input_str):
    # Chu·∫©n h√≥a chu·ªói v·ªÅ d·∫°ng t·ªï h·ª£p (NFD)
    nfkd_form = unicodedata.normalize('NFD', input_str)

    # Lo·∫°i b·ªè c√°c k√Ω t·ª± thu·ªôc d·∫°ng d·∫•u (Mn - Mark, Nonspacing) b·∫±ng bi·ªÉu th·ª©c ch√≠nh quy
    no_accent_str = re.sub(r'[\u0300-\u036f]', '', nfkd_form)

    # Thay th·∫ø c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát nh∆∞ ƒê v√† ƒë
    no_accent_str = no_accent_str.replace('ƒê', 'D').replace('ƒë', 'd')

    return no_accent_str.lower()


def get_url(url):
    if url == "":
        return ""
    match = re.search(r'(http[^\s]+\.(jpg|JPG|png|PNG|jpeg|JPEG))', url)
    return match.group(1)


def disPlay_Info(id):
    doc_ref = db.collection('face-vertificate').document(str(id))
    doc = doc_ref.get()
    doc_data = doc.to_dict()
    Ten = doc_data.get('hoten')
    Masv = doc_data.get('masv')
    # Nganh = doc_data.get('Nganh')
    url_ChanDung = doc_data.get('ChanDung')
    url_TheSV = doc_data.get('TheSV')
    c1, c2 = st.columns(2)
    c1.write("T√™n: " + Ten)
    c2.write("M√£ sv: " + Masv)

    url_CD = get_url(url_ChanDung)
    url_TSV = get_url(url_TheSV)
    if url_CD != "":
        c1.write("·∫¢nh ch√¢n dung")
        c1.image(url_CD, width=300)
    else:
        c1.write("·∫¢nh ch√¢n dung: Ch∆∞a c√≥ ·∫£nh")
    if url_TSV != "":
        c2.write("Th·∫ª sv")
        c2.image(url_TSV, width=300)
    else:
        c2.write("Th·∫ª SV: Ch∆∞a c√≥ ·∫£nh")


def normalize_Name():
    lst_name = []
    lst_ten, a, b, c = get_Info()
    for i in range(len(lst_ten)):
        lst_name.append(remove_accents(lst_ten[i]))
    return lst_name


def Add_Student(Ten="", Masv="", url_ChanDung="", url_TheSV=""):
    data = {
        'hoten': Ten,
        'masv': Masv,
        'ChanDung': url_ChanDung,
        'TheSV': url_TheSV
    }
    doc = db.collection('face-vertificate').get()
    document_id = len(doc) + 1
    document_id = str(document_id)
    doc_ref = db.collection(
        'face-vertificate').document(document_id).create(data)


def normalize_TheSV(lst_TheSV):
    for i in range(len(lst_TheSV)):
        lst_TheSV[i] = lst_TheSV[i].lower()
    return lst_TheSV


# type = 1: Ch√¢n dung, type = 2: Th·∫ª sv
def Add_url_with_Id(id, public_url, type):
    doc_ref = db.collection('face-vertificate').document(str(id))
    if type == 1:
        doc_ref.update({
            'ChanDung': public_url
            # 'url_TheSV': public_url2
        })
    else:
        doc_ref.update({
            # 'url_ChanDung': public_url,
            'TheSV': public_url
        })


def Add_Image(uploaded_file, name_file, id, type):
    if uploaded_file is not None:
        # L∆∞u ·∫£nh v√†o t·∫°m th·ªùi
        with tempfile.NamedTemporaryFile(delete=False) as temp_file:
            temp_file.write(uploaded_file.read())
            temp_file_name = temp_file.name

        # ƒê·∫∑t t√™n file khi upload
        # Thay 'images/' b·∫±ng ƒë∆∞·ªùng d·∫´n trong bucket b·∫°n mu·ªën l∆∞u
        blob = bucket.blob(f"Add_images/{name_file}")

        # Upload file l√™n Firebase Storage
        blob.upload_from_filename(temp_file_name)

        # T·∫°o URL cho file v·ª´a upload
        blob.make_public()

        public_url = blob.public_url
        url = f"<img src = '{public_url}' width='100'>"
        Add_url_with_Id(id, url, type)


def CRUD():
    c1, c2, c3, c4 = st.columns(4)

    col_name, col_Masv = st.columns(2)

    lst_Ten, lst_Masv, lst_ChanDung, lst_TheSV = get_Info()
    # T√¨m ki·∫øm
    if 'search_clicked' not in st.session_state:
        st.session_state.search_clicked = False

    if 'add_clicked' not in st.session_state:
        st.session_state.add_clicked = False

    if 'update_clicked' not in st.session_state:
        st.session_state.update_clicked = False

    if 'deleted_clicked' not in st.session_state:
        st.session_state.deleted_clicked = False

    if c1.button('T√¨m ki·∫øm'):
        st.session_state.search_clicked = True
        st.session_state.add_clicked = False
        st.session_state.update_clicked = False
        st.session_state.deleted_clicked = False

    if c2.button('Th√™m'):
        st.session_state.search_clicked = False
        st.session_state.add_clicked = True
        st.session_state.update_clicked = False
        st.session_state.deleted_clicked = False
    if c3.button("S·ª≠a"):
        st.session_state.add_clicked = False
        st.session_state.search_clicked = False
        st.session_state.update_clicked = True
        st.session_state.deleted_clicked = False

    if c4.button("X√≥a"):
        st.session_state.add_clicked = False
        st.session_state.search_clicked = False
        st.session_state.update_clicked = False
        st.session_state.deleted_clicked = True

    if st.session_state.search_clicked:
        Input_name = col_name.text_input("HoTen")
        Input_Masv = col_Masv.text_input("MaSV")

        Input_name = remove_accents(Input_name)
        Input_Masv = remove_accents(Input_Masv)
        lst_id = []
        lst_name = normalize_Name()
        lst_TheSV = normalize_TheSV(lst_TheSV)

        if st.button("Xong"):
            st.cache_data.clear()
            if Input_name != "":
                for i in range(len(lst_name)):
                    if Input_name in lst_name[i]:
                        lst_id.append(i + 1)
            if Input_Masv != "":
                for i in range(len(lst_TheSV)):
                    if Input_Masv in lst_TheSV[i]:
                        lst_id.append(i + 1)
            if Input_name == "" and Input_Masv == "":
                lst_id = np.arange(1, len(lst_name) + 1, 1)
            lst_id = np.array(lst_id)
            lst_id = np.unique(lst_id)
            for i in lst_id:
                disPlay_Info(i)

    # Th√™m

    if st.session_state.add_clicked:
        Input_name_add = col_name.text_input("Nh·∫≠p HoTen")
        Input_Masv_add = col_Masv.text_input("Nh·∫≠p MaSV")

        col_1, col_2 = st.columns(2)

        AnhChanDung_upload = col_1.file_uploader(
            "T·∫£i ·∫£nh ch√¢n dung c·ªßa b·∫°n", type=["png", "jpg", "jpeg"])
        TheSV_upload = col_2.file_uploader(
            "T·∫£i ·∫£nh th·∫ª sv c·ªßa b·∫°n", type=["png", "jpg", "jpeg"])
        if st.button('Xong '):
            st.cache_data.clear()
            if Input_name_add == "" and Input_Masv_add == "":
                st.markdown(
                    "##### Ch√∫ √Ω: B·∫°n ph·∫£i nh·∫≠p ƒë·∫ßy ƒë·ªß **H·ªç T√™n** v√† **M√£ sinh vi√™n**")
            else:
                Add_Student(Ten=Input_name_add, Masv=Input_Masv_add,
                            url_ChanDung="", url_TheSV="")
                id = len(lst_TheSV) + 1
                Name_1 = remove_accents(Input_name_add)
                unique_id = str(int(time.time())) + \
                    str(random.randint(1000, 9999))
                Name_1 = Name_1.replace(" ", "") + \
                    str(unique_id) + "AnhChanDung.jpg"

                Name_2 = remove_accents(Input_Masv_add)
                Name_2 = Name_2.replace(" ", "") + str(unique_id) + "TheSV.jpg"

                Add_Image(AnhChanDung_upload, Name_1, id, 1)
                Add_Image(TheSV_upload, Name_2, id, 2)

    # S·ª≠a
    if st.session_state.update_clicked:
        selected_name = st.selectbox(
            "Ch·ªçn sinh vi√™n mu·ªën ch·ªânh s·ª≠a th√¥ng tin", lst_Ten)
        id = 0
        for i in range(len(lst_Ten)):
            if lst_Ten[i] == selected_name:
                id = i
                break
        c1, c2 = st.columns(2)
        text_1 = c1.text_input("Nh·∫≠p t√™n c·∫ßn s·ª≠a: ", selected_name)
        text_2 = c2.text_input("Nh·∫≠p m√£ sv c·∫ßn s·ª≠a: ", lst_Masv[id])

        image_upload_1 = c1.file_uploader(
            "Ch·ªçn ·∫£nh ch√¢n dung c·∫ßn thay th·∫ø", type=["png", "jpg", "jpeg"])
        image_upload_2 = c2.file_uploader(
            "Ch·ªçn ·∫£nh th·∫ª sv c·∫ßn thay th·∫ø", type=["png", "jpg", "jpeg"])

        if st.button("Xong"):
            st.cache_data.clear()
            doc_ref = db.collection('face-vertificate').document(str(id + 1))
            doc_ref.update({
                "hoten": text_1,
                "masv": text_2
            })
            if image_upload_1 is not None:
                Name_1 = remove_accents(text_1)
                unique_id = str(int(time.time())) + \
                    str(random.randint(1000, 9999))
                Name_1 = Name_1.replace(" ", "") + \
                    str(unique_id) + "AnhChanDung.jpg"
                Add_Image(image_upload_1, Name_1, id + 1, 1)
            if image_upload_2 is not None:
                Name_2 = remove_accents(text_2)
                unique_id = str(int(time.time())) + \
                    str(random.randint(1000, 9999))
                Name_2 = Name_2.replace(" ", "") + str(unique_id) + "TheSV.jpg"
                Add_Image(image_upload_2, Name_2, id + 1, 2)
    # X√≥a
    if st.session_state.deleted_clicked:
        selected_name = st.selectbox(
            "Ch·ªçn sinh vi√™n mu·ªën x√≥a th√¥ng tin", lst_Ten)
        if st.button("X√≥a sinh vi√™n"):
            st.cache_data.clear()
            # st.warning("B·∫°n c√≥ ch·∫Øc ch·∫Øn mu·ªën x√≥a kh√¥ng")
            col1, col2 = st.columns([1, 1])
            with col1:
                doc = db.collection("face-vertificate").stream()
                # if st.button("C√≥"):
                st.cache_data.clear()
                for i in doc:
                    doc_data = i.to_dict()
                    Ten = doc_data.get('hoten')
                    print(Ten)
                    # Masv = doc_data.get('Ma_sinh_vien')
                    if Ten == selected_name:
                        db.collection(
                            "face-vertificate").document(i.id).delete()
                        st.success("X√≥a th√†nh c√¥ng")
                        break


            # with col2:
            #     if st.button("Kh√¥ng"):
            #         canceled = 1
# Valid combinations of backends and targets
backend_target_pairs = [
    [cv.dnn.DNN_BACKEND_OPENCV, cv.dnn.DNN_TARGET_CPU],
    [cv.dnn.DNN_BACKEND_CUDA,   cv.dnn.DNN_TARGET_CUDA],
    [cv.dnn.DNN_BACKEND_CUDA,   cv.dnn.DNN_TARGET_CUDA_FP16],
    [cv.dnn.DNN_BACKEND_TIMVX,  cv.dnn.DNN_TARGET_NPU],
    [cv.dnn.DNN_BACKEND_CANN,   cv.dnn.DNN_TARGET_NPU]
]

parser = argparse.ArgumentParser(
    description="SFace: Sigmoid-Constrained Hypersphere Loss for Robust Face Recognition (https://ieeexplore.ieee.org/document/9318547)")
parser.add_argument('--target', '-t', type=str,
                    help='Usage: Set path to the input image 1 (target face).')
parser.add_argument('--query', '-q', type=str,
                    help='Usage: Set path to the input image 2 (query).')
parser.add_argument('--model', '-m', type=str, default='face_recognition_sface_2021dec.onnx',
                    help='Usage: Set model path, defaults to face_recognition_sface_2021dec.onnx.')
parser.add_argument('--backend_target', '-bt', type=int, default=0,
                    help='''Choose one of the backend-target pair to run this demo:
                        {:d}: (default) OpenCV implementation + CPU,
                        {:d}: CUDA + GPU (CUDA),
                        {:d}: CUDA + GPU (CUDA FP16),
                        {:d}: TIM-VX + NPU,
                        {:d}: CANN + NPU
                    '''.format(*[x for x in range(len(backend_target_pairs))]))
parser.add_argument('--dis_type', type=int, choices=[0, 1], default=0,
                    help='Usage: Distance type. \'0\': cosine, \'1\': norm_l1. Defaults to \'0\'')
parser.add_argument('--save', '-s', action='store_true',
                    help='Usage: Specify to save file with results (i.e. bounding box, confidence level). Invalid in case of camera input.')
parser.add_argument('--vis', '-v', action='store_true',
                    help='Usage: Specify to open a new window to show results. Invalid in case of camera input.')
args = parser.parse_args()


# target_size: (h, w)
def visualize(img1, faces1, img2, faces2, matches, scores, target_size=[512, 512]):
    out1 = img1.copy()
    out2 = img2.copy()
    matched_box_color = (0, 255, 0)    # BGR
    mismatched_box_color = (0, 0, 255)  # BGR

    # Resize to 256x256 with the same aspect ratio
    padded_out1 = np.zeros(
        (target_size[0], target_size[1], 3)).astype(np.uint8)
    h1, w1, _ = out1.shape
    ratio1 = min(target_size[0] / out1.shape[0],
                 target_size[1] / out1.shape[1])
    new_h1 = int(h1 * ratio1)
    new_w1 = int(w1 * ratio1)
    resized_out1 = cv.resize(out1, (new_w1, new_h1),
                             interpolation=cv.INTER_LINEAR).astype(np.float32)
    top = max(0, target_size[0] - new_h1) // 2
    bottom = top + new_h1
    left = max(0, target_size[1] - new_w1) // 2
    right = left + new_w1
    padded_out1[top: bottom, left: right] = resized_out1

    # Draw bbox
    bbox1 = faces1[0][:4] * ratio1
    x, y, w, h = bbox1.astype(np.int32)
    cv.rectangle(padded_out1, (x + left, y + top),
                 (x + left + w, y + top + h), matched_box_color, 2)

    # Resize to 256x256 with the same aspect ratio
    padded_out2 = np.zeros(
        (target_size[0], target_size[1], 3)).astype(np.uint8)
    h2, w2, _ = out2.shape
    ratio2 = min(target_size[0] / out2.shape[0],
                 target_size[1] / out2.shape[1])
    new_h2 = int(h2 * ratio2)
    new_w2 = int(w2 * ratio2)
    resized_out2 = cv.resize(out2, (new_w2, new_h2),
                             interpolation=cv.INTER_LINEAR).astype(np.float32)
    top = max(0, target_size[0] - new_h2) // 2
    bottom = top + new_h2
    left = max(0, target_size[1] - new_w2) // 2
    right = left + new_w2
    padded_out2[top: bottom, left: right] = resized_out2

    # Draw bbox
    assert faces2.shape[0] == len(
        matches), "number of faces2 needs to match matches"
    assert len(matches) == len(
        scores), "number of matches needs to match number of scores"
    for index, match in enumerate(matches):
        bbox2 = faces2[index][:4] * ratio2
        x, y, w, h = bbox2.astype(np.int32)
        box_color = matched_box_color if match else mismatched_box_color
        cv.rectangle(padded_out2, (x + left, y + top),
                     (x + left + w, y + top + h), box_color, 2)

        score = scores[index]
        text_color = matched_box_color if match else mismatched_box_color
        cv.putText(padded_out2, "{:.2f}".format(
            score), (x + left, y + top - 5), cv.FONT_HERSHEY_DUPLEX, 0.4, text_color)

    return np.concatenate([padded_out1, padded_out2], axis=1)


def YuNet_and_Sface():
    st.markdown("#### 2. ·ª®ng d·ª•ng x√°c th·ª±c khu√¥n m·∫∑t v√† th·∫ª sinh vi√™n")
    threshold = st.slider(
        "Ch·ªçn ng∆∞·ª°ng **Confident Threshold:** ", 0.0, 1.0, 0.75)
    st.markdown("##### * M·ªôt s·ªë l∆∞u √Ω:")
    st.write(" - ƒê·ªÉ ƒë·∫£m b·∫£o k·∫øt qu·∫£ t·ªët nh·∫•t th√¨ ·∫£nh ph·∫£i kh√¥ng b·ªã m·ªù, nhi·ªÖu")
    st.write(" - ·∫¢nh kh√¥ng nh·∫Øm m·∫Øt, kh√¥ng ƒë∆∞·ª£c nghi√™ng qu√° nhi·ªÅu (n√™n s·ª≠ d·ª•ng nh·ªØng ·∫£nh nh√¨n tr·ª±c di·ªán)")
    st.write(" - ·ª®ng d·ª•ng n√†y c√≥ th·ªÉ x√°c th·ª±c khu√¥n m·∫∑t c√≥ k√≠ch th∆∞·ªõc t·ª´ **10x10** ƒë·∫øn **300x300** pixels")
    backend_id = backend_target_pairs[args.backend_target][0]
    target_id = backend_target_pairs[args.backend_target][1]
    # Instantiate SFace for face recognition
    recognizer = SFace(modelPath='./services/Face_Vertification/models/face_recognition_sface_2021dec.onnx',
                       disType=args.dis_type,
                       backendId=backend_id,
                       targetId=target_id)
    # Instantiate YuNet for face detection
    detector = YuNet(modelPath='./services/Face_Vertification/models/face_detection_yunet_2023mar.onnx',
                     inputSize=[320, 320],
                     confThreshold=threshold,
                     nmsThreshold=0.3,
                     topK=5000,
                     backendId=backend_id,
                     targetId=target_id)
    c1, c2 = st.columns(2)
    image1 = c1.file_uploader("T·∫£i ·∫£nh 1", type=["png", "jpg", "jpeg"])
    image2 = c2.file_uploader("T·∫£i ·∫£nh 2", type=["png", "jpg", "jpeg"])
    if image1 is not None and image2 is not None:
        img1 = Image.open(image1)
        img1 = ImageOps.exif_transpose(img1)
        img1 = cv.cvtColor(np.array(img1), cv.COLOR_RGB2BGR)

        img2 = Image.open(image2)
        img2 = ImageOps.exif_transpose(img2)
        img2 = cv.cvtColor(np.array(img2), cv.COLOR_RGB2BGR)
        # scale ·∫£nh ch√¢n dung
        max_size = 250
        w = min(img2.shape[1], max_size)
        h = w * img2.shape[0] // img2.shape[1]
        img2 = cv.resize(img2, (w, h))
    # Detect faces
        detector.setInputSize([img1.shape[1], img1.shape[0]])
        faces1 = detector.infer(img1)
        # assert faces1.shape[0] > 0, 'Cannot find a face in {}'.format(args.target)
        detector.setInputSize([img2.shape[1], img2.shape[0]])
        faces2 = detector.infer(img2)
        # assert faces2.shape[0] > 0, 'Cannot find a face in {}'.format(args.query)

        # Match
        if len(faces1) == 0:
            st.markdown("Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t ·ªü **·∫¢nh 1**")
        if len(faces2) == 0:
            st.markdown("Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t ·ªü **·∫¢nh 2**")
        if len(faces1) > 0 and len(faces2) > 0:
            scores = []
            matches = []
            for face in faces2:
                result = recognizer.match(
                    img1, faces1[0][:-1], img2, face[:-1])
                scores.append(result[0])
                matches.append(result[1])

            # Draw results
            image = visualize(img1, faces1, img2, faces2, matches, scores)
            if st.button("Submit"):
                st.image(image, channels="BGR")


def get_image_with_url(url):
    response = requests.get(url)
    if response.status_code == 200:
        image = Image.open(BytesIO(response.content))
        image = cv.cvtColor(np.array(image), cv.COLOR_RGB2BGR)
        return image
    return None


def Verification_with_Class():
    st.markdown("#### 3. ·ª®ng d·ª•ng nh·∫≠n di·ªán khu√¥n m·∫∑t trong l·ªõp h·ªçc")
    thresh = st.slider("Ch·ªçn ng∆∞·ª°ng **Confident Threshold** ", 0.0, 1.0, 0.80)
    st.markdown("##### * M·ªôt s·ªë l∆∞u √Ω:")
    st.write(" - ƒê·ªÉ ƒë·∫£m b·∫£o k·∫øt qu·∫£ t·ªët nh·∫•t th√¨ ·∫£nh ph·∫£i kh√¥ng b·ªã m·ªù, nhi·ªÖu")
    st.write(" - ·ª®ng d·ª•ng n√†y c√≥ th·ªÉ nh·∫≠n di·ªán khu√¥n m·∫∑t c√≥ k√≠ch th∆∞·ªõc t·ª´ **10x10** ƒë·∫øn **300x300** pixels")
    backend_id = backend_target_pairs[0][0]
    target_id = backend_target_pairs[0][1]
    # Instantiate SFace for face recognition
    recognizer = SFace(modelPath='./services/Face_Vertification/models/face_recognition_sface_2021dec.onnx',
                       disType=0,
                       backendId=backend_id,
                       targetId=target_id)
    # Instantiate YuNet for face detection
    detector = YuNet(modelPath='./services/Face_Vertification/models/face_recognition_sface_2021dec.onnx',
                     inputSize=[320, 320],
                     confThreshold=thresh,
                     nmsThreshold=0.3,
                     topK=5000,
                     backendId=backend_id,
                     targetId=target_id)
    c1, c2 = st.columns(2)
    dataset_image = []
    # path_dataset = './images/Faces_dataset'
    lst_Ten, lst_Masv, lst_ChanDung, lst_TheSV = get_Info()
    lst_image = []
    lst_dataset = []
    lst_image_path = []
    dataset_feature = []
    # L·∫•y ·∫£nh t·ª´ Dataset
    for i in range(len(lst_ChanDung)):
        if lst_ChanDung[i] == "":
            continue
        img = get_image_with_url(get_url(lst_ChanDung[i]))
        if img is None:
            continue
        lst_image_path.append(remove_accents(lst_Ten[i]))
        max_size = 640
        w = min(img.shape[1], max_size)
        h = w * img.shape[0] // img.shape[1]
        img = cv.resize(img, (w, h))
        detector.setInputSize([img.shape[1], img.shape[0]])
        faces_dataset = detector.infer(img)
        # Tr√≠ch xu·∫•t ƒë·∫∑c tr·ª´ng t·ª´ng khu√¥n m·∫∑t trong dataset
        for face in faces_dataset:
            dataset_feature.append((recognizer.infer(img, face[:-1]), i))

    image_uploaded = st.file_uploader(
        "T·∫£i ·∫£nh l·ªõp h·ªçc", type=["png", "jpg", "jpeg"])
    if image_uploaded is not None:
        image_class = Image.open(image_uploaded)
        image_class = ImageOps.exif_transpose(image_class)
        image_class = cv.cvtColor(np.array(image_class), cv.COLOR_RGB2BGR)
        res_image = image_class.copy()
        detector.setInputSize([image_class.shape[1], image_class.shape[0]])
        faces = detector.infer(image_class)
        features_class = []
        for face_class in faces:
            features_class.append(recognizer.infer(
                image_class, face_class[:-1]))
        lst_results_id = []
        lst_name = []
        for (feature_dt, id) in dataset_feature:
            best_score = 0.4
            best_id = -1
            id_path = -1
            for i in range(len(faces)):
                feature_dt = np.asarray(feature_dt)
                features_class[i] = np.asarray(features_class[i])
                results = recognizer.match_ft(feature_dt, features_class[i])
                score, match = results[0], results[1]
                if match == 1 and score > best_score:
                    best_score = score
                    best_id = i
                    id_path = id
            if best_id != -1:
                # print(lst_image_path[id_path], best_score)
                x, y, w, h = map(int, faces[best_id][:4])
                res_image = cv.rectangle(
                    res_image, (x, y), (x + w, y + h), (0, 255, 0), 2)
                res_image = cv.putText(res_image, lst_image_path[id_path], (
                    x, y - 5), cv.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
                lst_name.append(lst_Ten[id_path])
                lst_results_id.append(best_id)
        mark = {}
        for i in range(len(faces)):
            mark[i] = 0
        for i in range(len(lst_results_id)):
            idx = lst_results_id[i]
            mark[idx] = 1
        for i in range(len(faces)):
            if mark[i] == 0:
                x, y, w, h = map(int, faces[i][:4])
                res_image = cv.rectangle(
                    res_image, (x, y), (x + w, y + h), (0, 0, 255), 2)
        if st.button("Ti·∫øn h√†nh nh·∫≠n di·ªán"):
            st.markdown("Danh s√°ch c√°c sinh vi√™n c√≥ m·∫∑t trong l·ªõp:")
            for i in range(len(lst_name)):
                st.write(" - " + lst_name[i])
            st.image(res_image, channels="BGR")


def App():
    st.markdown("#### 1. Th√¥ng tin sinh vi√™n")
    get_Info()
    CRUD()
    Table_of_Data()
    YuNet_and_Sface()
    Verification_with_Class()


# App()
